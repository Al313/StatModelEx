---
title:  
    "Day6 exercise solutions"
date: 
    "Oct. 21st, 2024"
author:  
    "Ali Movasati, Isabelle Cretton, Tristan Koning"  
output:  
    pdf_document:
        latex_engine: xelatex
---


```{r global options}

# Set global code chunk options
knitr::opts_chunk$set(warning = FALSE)

```


```{r libraries}


# load required libraries
library(skimr)
library(ggplot2)
library(ggpubr)
library(magrittr)
library(tidyr)
library(dplyr)
library(tibble)
library(lme4)
library(lattice)
library(reshape2)


# define functions
`%notin%` <- Negate(`%in%`)


```


# Problem 1

## 1.A)
```{r}
# Load data
hearing <-  read.table(file = "data/hearing.txt", sep = "\t", header = TRUE)
hearing <- within(hearing, {
  ListID <- factor(ListID, levels = c("List1", "List2", "List3", "List4"))
})
skim(hearing)

# Graphical summeries
# Boxplot of scores by ListID
hearing %>% ggplot(aes(x = ListID, y = Hearing, color = ListID)) +
        geom_boxplot() +
        geom_jitter(width = 0.1, aes(color = factor(ListID)), size = 2) +
        theme_minimal()

# Scatterplot of subjectids on hearing scores
ggplot(hearing, aes(x = SubjectID, y = Hearing, color = ListID)) +
  geom_point() +
  labs(title = "Scatterplot of Scores by SubjectID", x = "SubjectID", y = "Score")

```

## 1.B)

```{r}
model_A <- lm(Hearing ~ ListID, data = hearing)
sum_model_A <- summary(model_A)
```

### << comments >>

Only `r round(sum_model_A$adj.r.squared*100, digits = 2)`% of variability in hearing measures are explained by different lists

We have enough evidence to state that the mean hearing score for List 3 and 4 are different than list 1, while for list 2 we cannot state that!

## 1.C)

```{r}

# fit the mixed model
lm_mixed <- lmer(Hearing ~ 1 + ListID + (1|SubjectID), data = hearing)

sum_model_mixed <- summary(lm_mixed)

print(sum_model_mixed)

# fit the model without ListID (null model)
lm_mixed_null <- lmer(Hearing ~ (1 | SubjectID), data = hearing)

sum_model_mixed_null <- summary(lm_mixed_null)

# Likelihood ratio test
anova(lm_mixed_null, lm_mixed)
```

### << comments >>

The more complex model with ListID as a fixed effect is significantly more accurate at representing the data than the simpler model. 

## 1.D)

Both models from 1.B and 1.C have the same estimates.

# Exercise 2

## (a)
```{r}
termites <- read.table(file = "data/termites.txt", sep = " ", header = TRUE)
# Remove NA entries
termites <- termites %>% select_if(~ !any(is.na(.)))

# EDA
skim(termites)
```

## (b)
```{r}
# Reshape data
termites <- melt(termites, id.vars = c("dish", "dose"), 
                  variable.name = "day",
                  value.name = "measurement")
str(termites)

# Convert day to numeric
termites$day <- as.numeric(gsub("day", "", as.character(termites$day)))

# Graphical EDA
lattice::xyplot(measurement ~ as.numeric(gsub("day", "", day)) | as.factor(dish), 
       data = termites, type = "l",
       layout = c(4, 4),
       main = "Measurements Over Time for Each Dish",
       xlab = "Days", ylab = "Measurement")

# bwplot of measurements distribution across days
lattice::bwplot(measurement ~ as.numeric(gsub("day", "", day)) | as.factor(dish), 
       data = termites,
       main = "Measurement Distribution Across Days",
       xlab = "Days", ylab = "Measurement")
```

## (c)
```{r}
# Fit a linear model
model_A <- lm(measurement ~ dose + day + dish, data = termites)
summary(model_A)

termites$predicted_A <- predict(model_A)

# Plot model
ggplot(termites, aes(x = as.numeric(gsub("day", "", day)), y = measurement, color = as.factor(dish))) +
  facet_wrap(~dose) +
  geom_point() +
  geom_line(aes(y = predicted_A)) +
  labs(title = "Model A: Predicted Values by Day and Dish", x = "Day", y = "Measurement")
```

### << comments >>

It is problematic to use dish as a dependent variable, as repeated measurements are taken on the same dish. This violates the assumption of independence of observations. 

## (d)

```{r}
# Fit a linear mixed model
model_B <- lmer(measurement ~ dose + day + (1 | dish), data = termites)
summary(model_B)
confint(model_B, method = "boot", nsim = 100, oldNames = FALSE)

termites$predicted_B <- predict(model_B)

# Plot model
ggplot(termites, aes(x = as.numeric(gsub("day", "", day)), y = measurement, color = as.factor(dish))) +
  facet_wrap(~dose) +
  geom_point() +
  geom_line(aes(y = predicted_B)) +
  labs(title = "Model B: Predicted Values by Day and Dish", x = "Day", y = "Measurement")
```

### << comments >>

The linear mixed model is more appropriate for this data as it accounts for the repeated measurements taken on the same dish, this can also be seen visually in the plots, where each prediction in model_B seem to be closer to the actual measurements compared to model_A. Dose now seems highly correlated with the measurements whereas in model_A it was not significant.

## (e)

```{r}
# Fit a linear mixed model
model_C <- lmer(measurement ~ dose + day + (day | dish) + day, data = termites)
summary(model_C)
confint(model_C, method = "boot", nsim = 100, oldNames = FALSE)

termites$predicted_C <- predict(model_C)

# Plot model
ggplot(termites, aes(x = as.numeric(gsub("day", "", day)), y = measurement, color = as.factor(dish))) +
  facet_wrap(~dose) +
  geom_point() +
  geom_line(aes(y = predicted_C)) +
  labs(title = "Model C: Predicted Values by Day and Dish", x = "Day", y = "Measurement")
```

### << comments >>

Again, this model seems to be more accurate than the previous models. 

## (f)

```{r}
boostrap_ci <- function(data, formula, parameter, N = 1000, conf = 0.90) {
  estimates <- numeric(N)

  for (i in 1:N) {
    resample <- data[sample(nrow(data), replace = TRUE), ]
    model <- lmer(formula, data = resample)
    estimates[i] <- fixef(model)[[parameter]]
  }

  return(quantile(estimates, c((1 - conf) / 2, 1 - (1 - conf) / 2)))
}

ci <- boostrap_ci(termites, measurement ~ dose + day + (1 | dish) + day, "dose")
ci
```

### << comments >>

The 90% confidence interval excludes 0, therefore we can say that dose significantly impact survival!